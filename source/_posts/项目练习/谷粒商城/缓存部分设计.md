---
title: 谷粒商城-分布式缓存设计
type:
comments:
tags: 
  - 分布式
  - 微服务
  - SpringBoot
  - Redis
  - Spring Cache
categories: 
  - 项目练习
description: 
keywords: SpringCloud Redis
cover: https://w.wallhaven.cc/full/m9/wallhaven-m9873y.jpg
top_img: https://w.wallhaven.cc/full/m9/wallhaven-m9873y.jpg
---

## Redis 缓存

为了系统性能的提升，我们一般都会将部分数据放入缓存中，加速访问。而 db 数据库承担数据落盘工作。 

那么哪些数据适合放入缓存呢？

1）即时性、数据一致性要求不高的；

2）访问量大且更新频率不高的数据（读多，写少的情况） 。

拥有缓存的查询逻辑执行过程：

![](https://pic1.imgdb.cn/item/635504f116f2c2beb1345ea4.png)

可以使用本地缓存（例如 Map 缓存），在负载均衡情况下可能会出现 `数据不一致` 的情况，因此分布式情况下应该使用分布式缓存方案（例如 `Redis` ）。

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12374488/1630841046633-826f06c2-b178-4c26-8ea6-a069cfb422eb.png)

### 整合 Redis

1、引入 redis-starter 依赖：

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2、配置 redis 连接信息：

```yml
spring:
	redis: 
    	host: 8.142.92.222
    	port: 6666
```

测试使用：

```java
@RunWith(SpringRunner.class)
@SpringBootTest
public class ShopProductApplicationTests {

    // 引入 redis 操作对象：StringRedisTemplate
	@Autowired
	StringRedisTemplate redisTemplate;

	@Test
	public void contextLoads() {
		ValueOperations<String, String> ops = redisTemplate.opsForValue();
		//保存数据
		ops.set("hello","world_"+ UUID.randomUUID().toString());
		//查询数据
		String hello = ops.get("hello");
		System.out.println(hello);
	}
}
```

3、整改原来的代码，加入 Redis 缓存功能：

```java
/** TODO:压力测试时发现会产生堆外内存溢出，主要是因为 Boot 默认使用 lettuce 作为操作 redis 的客户端
 * 1）lettuce 底层使用 Netty 进行网络通信
 * 2)lettuce 本身的 bug 导致 Netty 堆外内存（直接内存）溢出，因为如果没有指定对外内存，默认会使用设置的 -Xmx 的大小
 * 解决方案：
 * 1）调整 -Dio.netty.maxDirectMemory 的大小
 * 2）升级 lettuce，或者切换使用 Jedis 老版的方案（此处我并没有修改）
 */
@Override
public Map<String, List<Catelog2Vo>> getCatelogJson(){
    //加入缓存逻辑的实现:需要注意 Json 格式的相互转化（序列化和反序列化问题）
    String catelogJson = redisTemplate.opsForValue().get("catelogJson");
    if (StringUtils.isEmpty(catelogJson)){
        //判断缓存中是否存在,如果没有则从数据库查询，并将查询到的数据转为 Json 插入到缓存
        Map<String, List<Catelog2Vo>> catelogJsonFromDB = this.getCatelogJsonFromDB();
        redisTemplate.opsForValue().set("catelogJson", JSON.toJSONString(catelogJsonFromDB));
        log.debug("完成 Redis 缓存的更新");
        return catelogJsonFromDB;
    }
    Map<String, List<Catelog2Vo>> result = JSON.parseObject(catelogJson, new TypeReference<Map<String, List<Catelog2Vo>>>(){});
    return result;
}

//从数据库查询并封装分类数据
public Map<String, List<Catelog2Vo>> getCatelogJsonFromDB() {
    //原来的 getCatelogJson 函数从数据库查询即可
}
```

### 缓存失效

`缓存穿透`问题是指查询一个一定不存在的数据，因此`缓存肯定查不到，数据库也查不到`，那么就会导致每次请求都还是会打到数据库，可能会导致数据库崩溃，失去了缓存的意义。可采用 `缓存 null 结果或是标志位缓存，并加入短暂过期时间` 的方案来解决。

`缓存雪崩`问题是指设置缓存时采用相同的的过期时间，也就导致了`缓存大面积集体失效`，数据库压力骤增，甚至崩溃。可采用 `失效时间基础上增加随机值，让缓存过期时间重复率下降` 的方式来解决。

`缓存击穿`问题是指某一个高频热点数据缓存失效时突然来了大量请求该数据，呆滞缓存击穿。开率使用 `加锁` 的方式使请求串行执行来解决。

因此上面的缓存添加方式还需要优化：

1、添加缓存过期时间：

```java
redisTemplate.opsForValue().set("catelogJson", JSON.toJSONString(catelogJsonFromDB), 1, TimeUnit.DAYS);
```

2、加锁：使用 `synchronized/Lock` 本地进程锁同步资源或是使用 `分布式锁`。

1）本地锁方案：如果是 `synchronized(this)` 或是直接加到方法上，由于 SpringBoot Bean 默认单例，因此能够实现加锁同步让请求串行执行。但是分布式场景下，某个服务都会是多个同时部署，但是 this 只代表当前容器里面的 Bean，因此只能锁住当前服务的该对象，也就是说还是会有多个请求能够打进系统，多少个服务就可能有多少个请求同时打进数据库，因此就需要 `分布式锁` 来整体控制请求 (实际上服务不多的情况下也可以接受)。

2）分布式锁方案：主要考虑使用 Redis 的 nx 操作来实现。

1 > 首先考虑使用 Redis 的 `set nx 和 ex` 原子性命令来实现分布式锁，但是如果业务代码执行过程中出现异常或是执行业务时机器断电了，那么`释放锁过程就没有执行`，就可能会导致死锁，因此使用此种方式时`锁必须设定过期时间`（同时还必须和之前的操作是原子操作，避免命令之间出现故障不释放锁），能够自动删除。

```java
Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", "1", 30, TimeUnit.SECONDS);	//加锁并同时设置过期时间
if (lock) {  
    //加锁成功，执行业务
    业务代码
    //释放锁
    redisTemplate.delete("lock");
} else {
    //说明有客户端先建立了连接，加锁失败，进行重试
    return getCatelogJson();
}
```

2 > 但是设置锁的过期时间还会出现问题：业务未执行完成时锁已经过期，那么就可能导致很多问题：

- 问题一：删除 redis 中已经过期不存在的数据。
- 问题二：锁最初被客户端 c1 拥有，锁过期时 c1 还未执行完毕，锁被其他 client 拿到，其他线程还未执行完毕自己的业务时，c1 又会执行删锁的逻辑，而且实际上`删除的是其他 client 拥有的锁`，那么就导致后面的 client 请求的锁同时失效，造成更多的 client 拿到锁，蝴蝶效应。

那么实际上 lock 中的 value 就不能存储一个相同的锁标志位，而是应该给每个 client 一个特定的标志：`UUID` 。

```java
String uuid = UUID.randomUUID().toString();
Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 30, TimeUnit.SECONDS);
if (lock) {
    //加锁成功，先执行业务，再释放锁
    // ......业务代码......
    // 当删除锁时则需要先判断目前的锁是不是自己放的那个锁
    String lockValue = redisTemplate.opsForValue().get("lock");
    if (uuid.equals(lockValue)){
        redisTemplate.delete("lock");
    }
} else {
    //说明有客户端先建立了连接，加锁失败，进行重试
    return getCatelogJson();
}
```

​	但实际上还是存在问题：假如业务执行完毕后，get("lock") 获取过程比较漫长(网络交互)，刚获取到 lock 值还没过期，但是在数据回传到业务代码时 lock 就过期了，同时另一个 client 设置的锁的 key 也叫 lock ，那么还是可能会删除其他 client 的锁。

​	而这种问题的解决办法就得`采用 Lua 脚本来将获取 lock 值和删除 lock 过程变为一个原子操作来解锁`。

```lua
String uuid = UUID.randomUUID().toString();
Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
if (lock) {
     try {
         //加锁成功，先执行业务，再释放锁
         // ......业务代码......
     }finally {
         // 使用 Lua 脚本来实现原子操作删除锁
         String luaScript = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
         redisTemplate.execute(new DefaultRedisScript<>(luaScript, Long.class), Arrays.asList("lock"), uuid);
     }
} else {
    //说明有客户端先建立了连接，加锁失败，进行重试
    Thread.sleep(200);
    return getCatelogJson();
}
```

3 > 使用封装好的方案：`Redisson 分布式锁` 方案。后续项目的分布式锁和分布式对象方案就是选择使用 Redisson 来实现。

### Redisson 方案实现

Redisson 就是在 Redis 基础上实现的 Java 语言的分布式锁的实现，提供了很多分布式服务。

1、引入 Redisson 的服务原生依赖（后续实际使用会引入 starter）。

```xml
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.12.0</version>
</dependency>
```

2、配置 redisson ，编写 redisson 配置类：

```java
@Configuration
public class RedissonConfig {
    //注入 RedissonClient 对象：所有对 Redisson 的操作都是通过这个对象
    @Bean(destroyMethod = "shutdown")
    public RedissonClient redissonClient() throws IOException {
        Config config = new Config();
        //使用单节点 redis 模式并设置远程 redis 地址
        config.useSingleServer().setAddress("redis://8.142.92.222:6666");
        return Redisson.create(config);
    }
}
```



3、Redisson 可重入锁实现。

基于 Redisson 实现可重入锁基本和 Java 的 Lock 接口相同，并且实现了 JUC Lock 的锁，因此使用上也基本没有区别，可以无缝切换。

```java
@ResponseBody
@GetMapping("/hello")
public String hello(){
    //获取锁，锁名相同即同一把锁
    RLock lock = redissonClient.getLock("my-lock");
    //阻塞式 "等待" 加锁后才能执行业务代码
    lock.lock();
    try {
        log.debug(Thread.currentThread().getName() + "加锁成功!!!");
        log.debug("开始执行业务代码......");
        Thread.sleep(30000);
        log.debug("执行业务代码完毕......");
    } catch (InterruptedException e) {
        e.printStackTrace();
    } finally {
        //解锁,推荐放在 finally 代码块
        lock.unlock();
        log.debug(Thread.currentThread().getName() + "解锁成功!!!");
    }
    return "hello";
}
```

开启两个窗口执行 /hello 请求，请求结果显示：

```shell
http-nio-10001-exec-1加锁成功!!!
开始执行业务代码......
执行业务代码完毕......
http-nio-10001-exec-1解锁成功!!!
http-nio-10001-exec-2加锁成功!!!
开始执行业务代码......
执行业务代码完毕......
http-nio-10001-exec-2解锁成功!!!
```

![](https://pic1.imgdb.cn/item/63563aa416f2c2beb19352c9.png)

`[问题]` 假设解锁代码没有运行(断电等等故障问题时)，Redisson 会不会出现死锁呢？

实际上这个问题很容易演示，两个服务一起抢锁，停掉其中一个，发现另一个可以拿到锁，因此`没有死锁问题`。同时还会发现当不停刷新锁数据（模拟业务操作时间过长）时，锁的有效时间（默认有效时间 30s ）变长了，也就是`自动续期`，实际上这是因为 Redisson 的`看门狗机制` 。

1）锁的自动续期：如果业务超长，运行期间会自动给锁续上新的 30s，不用担心业务时间过长导致锁自动过期而被删除。

2）加锁的业务只要运行完成，就不会给锁自动续期，即使不手动释放锁，锁默认也会在30s以后自动删除。

> 注意：如果指定锁key 的有效时间，那么`锁超时后就不会自动续期`，因此底层实际上就是调用 Lua 脚本来执行(未指定时间就会使用看门狗的默认时间 30s ，同时内部就会有定时任务( `看门狗时间/3` 执行一次)来重新设置过期时间为看门狗的默认时间)，因此需要注意自动解锁时间一定要大于业务的执行时间：
>
> ```java
> lock.lock(10, TimeUnit.SECONDS);
> ```

因此最佳实践是应该指定过期时间，省掉整个自动续期的操作，来手动解锁。



3、Redisson 读写锁实现。

​	基于 Redis 的 Redisson 分布式可重入读写锁 `RReadWriteLock` Java对象实现了 `JUC.ReadWriteLock` 接口，其中读锁和写锁都继承了 RLock 接口，因此分布式Redisson 读写锁特性仍然是允许同时有多个读锁（共享锁）和一个写锁（排他锁）处于加锁状态 ====> `读读并行，写读互斥，读写互斥，写写互斥` 。

```java
RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");
rwlock.readLock().lock();		//加读锁
rwlock.writeLock().lock();		//加写锁
```



4、Redisson 信号量 Semaphore 实现。

```java
@ResponseBody
@GetMapping("/park")
public String park() throws InterruptedException {
    RSemaphore park = redissonClient.getSemaphore("park");
    park.acquire(); //阻塞获取一个信号量（占用一个车位）
    return "park";
}

@ResponseBody
@GetMapping("/go")
public String go() throws InterruptedException {
    RSemaphore park = redissonClient.getSemaphore("park");
    park.release(); //释放一个信号量（释放一个车位）
    return "go";
}
```

因此根据上面的案例可以发现，信号量还可以做 `限流操作`，限制信号量数量来做分布式限流。



5、Redisson 闭锁 CountDownLatch 实现类似于 JUC 的闭锁实现。

```java
RCountDownLatch latch = redisson.getCountDownLatch("my-countDownLatch");
latch.trySetCount(5);
latch.await();		// 等待闭锁完成，计数到 0

//闭锁计数操作时也就是获取 CountDownLatch 来释放
RCountDownLatch latch = redisson.getCountDownLatch("my-countDownLatch");
latch.countDown();	//闭锁计数减1
```

### 缓存一致性

使用 Redisson 来改造原来的业务代码：

```java
public Map<String, List<Catelog2Vo>> getCatelogJsonWithRedisson(){
    RLock lock = redissonClient.getLock("catelogJson-lock");
    lock.lock();
    Map<String, List<Catelog2Vo>> catelogJsonFromDB = null;
    try {
        String catelogJson = redisTemplate.opsForValue().get("catelogJson");
        if (StringUtils.isEmpty(catelogJson)){
            log.debug("缓存未命中，查询数据库");
            catelogJsonFromDB = this.getCatelogJsonFromDB();
            log.debug("完成 Redis 缓存的新增");
        }else {
            log.debug("缓存命中,直接从缓存中获取数据");
            catelogJsonFromDB = JSON.parseObject(catelogJson, new TypeReference<Map<String, List<Catelog2Vo>>>(){});
        }

    }finally {
        lock.unlock();
    }
    return catelogJsonFromDB;
}
```

但是当数据修改 update 时，就可能会出现 `数据一致性问题：缓存数据如何和数据库保持一致`？

1）`双写模式`：数据库更改完毕后，读取数据库数据来替换缓存中的数据。

![](https://pic1.imgdb.cn/item/6356502016f2c2beb1cd1709.png)

2）`失效模式`：数据库更改完毕后，删除缓存中的数据，等待下一次主动查询时更新。

![](https://pic1.imgdb.cn/item/6356502b16f2c2beb1cd3230.png)

但是这两种方案还是都存在 `暂时性的脏数据问题`，都会导致缓存不一致问题，即多个实例同时更新时会出现问题，但都是能够保证 `最终一致性` 的。

因此缓存一致性的的解决方案：

1）如果是用户维度的数据（个人信息、订单数据等等），并发几率小，则缓存数据加上过期时间每隔一段时间就触发读数据的 `自动更新缓存` 即可。

2）如果是菜单数据、商品介绍等`能够容忍长时间的缓存不一致`的基本数据，可以不考虑解决，但也可以使用 canal 订阅 binlog 日志的方式。

![Canal工作原理及使用插图2](https://media.ntan520.com/2022/03/bacbb42280b714a6240119de37e11b83.png)

也就是说 `缓存数据 + 过期时间` 能够解决大部分业务对于缓存的要求，如果不能保证，可以通过 `加锁(特别是读写锁)` 来保证读读并发和读写互斥。

`[总结]` 本系统中的数据一致性解决方案：所有数据设置过期时间（`失效模式`），读写数据时，加上 `分布式读写锁`，非常适用于本系统中经常读取数据的情况。

## SpringCache

在上面的开发中发现，缓存的处理代码基本都一样，肯定就需要考虑抽取公共工具类或是其他方案，而 `Spring Cache` 就是 Spring 整合缓存的一套方案，用来统一缓存的实现，主要就是通过 `Cache(实际存储)` 和 `CacheManager(定义规则，包括 RedisCacheManager )` 两个接口实现，一个 Manager 管理多个 Cache 区域。

1、引入 SpringCache 和 Redis(此项目使用 Redis 作为缓存) 的启动类依赖：

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2、编写相关配置：

1）初始化自动配置：CacheAutoConfiguration 会根据选择器导入 `RedisCacheConfiguration` ，内部自动注入了 `RedisCacheManager` 。

2）需要手动配置的 Redis 信息：

```yml
spring: 
    cache:
        type: redis
    # 配置使用 Redis 作为缓存
    redis: 
        host: 8.142.92.222
        port: 6666
```

3）主启动类添加注解 `@EnableCaching` 。

4）在需要的分类上标注 `@Cacheable` 注解，代表当前方法的结果需要缓存，并且能够实现如果缓存有就不会调用方法，如果没有缓存就会调用方法并将方法执行结果放入缓存。但是`需要标注缓存的分区`，用于指定缓存数据应该放到哪个名字的缓存，推荐按照业务类型分区。

```java
/**
 * CategoryServiceImpl
 * 查询所有的一级分类
 * @return 一级分类集合
 */
@Cacheable(cacheNames = {"category"})
@Override
public List<CategoryEntity> getLevel1Categories() {
    QueryWrapper<CategoryEntity> wrapper = new QueryWrapper<>();
    wrapper.eq("parent_cid", 0);
    return this.baseMapper.selectList(wrapper);
}
```

> 默认设置：使用 Cacheable 不做其他设置时默认生成的缓存的 key 为 `SimpleKey`，而 value 的值默认是使用 `JDK自带序列化后的数据`，并且默认的过期时间 `ttl = -1`，也就是`永不过期`。

5）因此需要自定义一些信息：

设置指定 key 名称，可接受 SpEl 表达式：

```java
@Cacheable(cacheNames = {"category"}, key = "'level1Categories'")
```

设置过期时间 TTL：

```yml
spring: 
    cache:
    	redis： 
        	time-to-live: 360000   # ms 为单位
```

将数据保存为 Json 格式，而非默认的Jdk序列化格式，则需要在容器中放一个 `RedisCacheConfiguration` ，来替换原本的 `默认配置 defaultCacheConfig` 。

```java
@EnableConfigurationProperties(CacheProperties.class)  //开启属性配置绑定功能(CacheProperties 并不在 IOC 中)
@EnableCaching
@Configuration
public class MyRedisCacheConfiguration {

    @Bean
    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
        //指定 key 的序列化方式：StringRedisSerializer
        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        //指定 value 的序列化方式：GenericJackson2JsonRedisSerializer，也可以使用引入的 fastjson 序列化
        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
        //配置这个后原本的配置文件配置失效,因此需要将原来的 CacheProperties 重新进行配置(下面的部分就是原本的默认配置，现在配置是为了实现配置文件配置有效性)
        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }
        return config;
    }
}
```

其他还有一些个性化的设置：

```yml
spring:
  cache:
    redis:
      time-to-live: 360000
      key-prefix: CACHE_    # 配置缓存key名称的前缀，如果没指定就默认使用配置缓存的 "名称+::"
      use-key-prefix: true  # 配置是否使用前缀
      cache-null-values: true # 是否缓存空值，防止缓存穿透
```

6）上述是读模式下的缓存实现，那么更新数据时怎么实现缓存一致性呢？双写模式还是失效模式呢(`实际上使用的失效模式`)？

```java
@CacheEvict(value = "category", key = "'level1Categories'")     //失效模式的使用
@Transactional
@Override
public void updateDetail(CategoryEntity category) {
    this.updateById(category);
    categoryBrandRelationService.updateCategory(category.getCatId(), category.getName());
}
```

7）修改原来的查询所有菜单数据的方法为使用 SpringCache：实际就是在最初的 getCatelogJson 方法上添加注解即可。

```java
@Override
@Cacheable(value = {"category"}, key = "#root.methodName")
public Map<String, List<Catelog2Vo>> getCatelogJson() {
    //将数据库的信息一次性查出来
    List<CategoryEntity> selectList = this.baseMapper.selectList(null);
    //1.查出所有一级分类
    List<CategoryEntity> level1Categories = this.getParent_cid(selectList, 0L);
    //2.封装数据
    Map<String, List<Catelog2Vo>> cateMenuMap = level1Categories.stream().collect(Collectors.toMap(
        level1Category -> level1Category.getCatId().toString(),
        level1Category -> {
            //2.1 根据每一个一级分类查询对应的二级分类信息数据,使用 getParent_cid 方法获取数据
            List<CategoryEntity> categoryEntities = this.getParent_cid(selectList, level1Category.getCatId());
            //2.2 封装上面的二级分类信息到最终结果中
            List<Catelog2Vo> catelog2Vos = null;
            if (categoryEntities != null) {
                catelog2Vos = categoryEntities.stream().map(level2Cate -> {
                    Catelog2Vo catelog2Vo = new Catelog2Vo(
                        level2Cate.getCatId().toString(),
                        level2Cate.getName(),
                        level1Category.getCatId().toString(),
                        null
                    );
                    //2.3 寻找二级分类的三级分类信息进行封装,使用 getParent_cid 方法获取数据
                    List<CategoryEntity> level3CateList = this.getParent_cid(selectList, level2Cate.getCatId());
                    if (level3CateList != null) {
                        List<Catelog2Vo.Catalog3Vo> level3Cats = level3CateList.stream().map(level3Cate -> {
                            Catelog2Vo.Catalog3Vo catalog3Vo = new Catelog2Vo.Catalog3Vo(
                                level2Cate.getCatId().toString(),
                                level3Cate.getCatId().toString(),
                                level3Cate.getName()
                            );
                            return catalog3Vo;
                        }).collect(Collectors.toList());
                        catelog2Vo.setCatalog3List(level3Cats);
                    }
                    return catelog2Vo;
                }).collect(Collectors.toList());
            }
            return catelog2Vos;
        }));
    return cateMenuMap;
}
```

8）实际上更新菜单时需要删除这两个缓存数据，因此不能使用单一的 CacheEvict 注解，而应该使用 `Caching 同时进行多种缓存操作`。

```java
@Caching(evict = {
    @CacheEvict(value = "category", key = "'level1Categories'"),
    @CacheEvict(value = "category", key = "'getCatelogJson'")
})
```

> 双写模式则使用 `@CachePut` 注解，失效模式使用 `@CacheEvict` 注解。



`[分析]` 实际上 SpringCache 也存在一些不足之处：

1）缓存穿透：使用 `cache-null-values: true` 实现。

2）缓存击穿：SpringCache 的 CacheManager (RedisCacheManager) 可以生成很多 Cache (RedisCache) 组件负责缓存的读取，而其内部的 `put` 方法放入缓存并没有加锁，因此如果还要使用 SpringCache 的方案，那么就需要在对应的缓存方法上添加注解属性 `sync`，就会使用有锁的 `get` 方法。

```java
@Cacheable(cacheNames = {"category"}, key = "#root.method.name", sync = true)
```

3）缓存雪崩：指定过期时间 + 随机值来解决。

`[总结]` 因此 SpringCache 在读模式下表现还可以，但写模式并没有加锁处理，这也就说明：常规数据（读多写少，及时性一致性要求不高的情况下）完全可以使用 SpringCache，写模式下只需要设置缓存的过期时间就足够。而针对特殊数据则需要进行特殊处理。
